## ğŸ“  File Structure

```
2-CLIP/
â”‚
â”œâ”€â”€ [Code] CLIP/ 
â”‚   â”œâ”€â”€ data/                       
â”‚   â”‚   â”œâ”€â”€ flickr30k/
â”‚   â”‚   â”‚   â”œâ”€â”€ annotations/results_20130124.token
â”‚   â”‚   â”‚   â””â”€â”€ images/
â”‚   â”‚   â”‚   
â”‚   â”‚   â”œâ”€â”€ bert-base-uncased/
â”‚   â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”‚   â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â”‚   â”‚   â”œâ”€â”€ special_tokens_map.json.txt
â”‚   â”‚   â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â”‚   â”‚   â””â”€â”€ vocab.txt
â”‚   â”‚   â”‚   
â”‚   â”‚   â””â”€â”€ vit-base-patch16-224/
â”‚   â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”‚   â”‚   â”œâ”€â”€ preprocessor_config.json
â”‚   â”‚   â”‚   â””â”€â”€ pytorch_model.bin
â”‚   â”‚   
â”‚   â”œâ”€â”€ models/                     
â”‚   â”‚   â”œâ”€â”€ clip_model.py
â”‚   â”‚   â”œâ”€â”€ image_encoder.py
â”‚   â”‚   â””â”€â”€ text_encoder.py
â”‚   â”‚   
â”‚   â”œâ”€â”€ utils/                      
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ dataloader.py
â”‚   â”‚   
â”‚   â”œâ”€â”€ train.py                    # Main training script
â”‚   â”œâ”€â”€ evaluate.py                 # Evaluation script
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â””â”€â”€ gitignore                   # Git ignore rules
â”‚
â”œâ”€â”€ img/ 
â”‚
â”œâ”€â”€ [Paper] Learning-Transferable-Visual-Models-From-Natural-Language-Supervision
â”‚
â””â”€â”€ README.md                       # Project documentation
```

## ğŸ” Data Preparation Guide

### 1. Download BERT Model (bert-base-uncased)

**1.1 Model Page**: [bert-base-uncased on Hugging Face](https://huggingface.co/bert-base-uncased)

**1.2 Instructions**:

- Click on "Files and versions" tab
- Download the key files from the `data` folder in the File Structure module.
- Create directory: `./data/bert-base-uncased/`
- Place all downloaded files in this directory

### 2. Download ViT Model (vit-base-patch16-224)
**2.1 Model Page**: [vit-base-patch16-224 on Hugging Face](https://huggingface.co/google/vit-base-patch16-224)

**2.2 Instructions**:

- Click on "Files and versions" tab
- Download the key files from the `data` folder in the File Structure module.
- Create directory: `./data/vit-base-patch16-224/`
- Place all downloaded files in this directory

### 3. Download Flickr30K Dataset
**3.1 Official Website**: [Flickr30K Dataset](http://shannon.cs.illinois.edu/DenotationGraph/)

**3.2 Instructions**:

- Download:
   - Image archive (`flickr30k-images.tar.gz`)
   - Annotation file (`flickr30k.tar.gz`)
- Create directory structure:
   ```
   ./data/flickr30k/
   â”œâ”€â”€ images/
   â””â”€â”€ annotations/
   ```
- Extract images to `./data/flickr30k/images/`
- Place annotation file in `./data/flickr30k/annotations/`

**3.3 Example Data**

- **images (1000268201.jpg) :**

![å¯è§†åŒ–æ•°æ®é›†å›¾ç‰‡](./img/1000268201.jpg)

- **annotations :**

```
1000268201.jpg#0	A child in a pink dress is climbing up a set of stairs in an entry way .
1000268201.jpg#1	A little girl in a pink dress going into a wooden cabin .
1000268201.jpg#2	A little girl climbing the stairs to her playhouse .
1000268201.jpg#3	A little girl climbing into a wooden playhouse .
1000268201.jpg#4	A girl going into a wooden building .
```

